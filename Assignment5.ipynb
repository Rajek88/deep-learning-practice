{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##: Write a program to demonstrate the change in accuracy/loss/convergence time with change in optimizers like stochastic gradient descent, adam, adagrad, RMSprop and Nadam for any suitable application\n",
        "\n",
        "Objectives:\n",
        "1. To learn optimization algorithms\n",
        "2. To learn and understand hyperparameters\n",
        "\n",
        "\n",
        "Theory:\n",
        "\n",
        "\n",
        "SGD, Adam, RMSprop, Nadam\n",
        "The word ‘stochastic‘means a system or a process that is linked with a random probability. Hence, in\n",
        "Stochastic Gradient Descent, a few samples are selected randomly instead of the whole data set for\n",
        "each iteration. In Gradient Descent, there is a term called “batch” which denotes the total number of\n",
        "samples from a dataset that is used for calculating the gradient for each iteration. In typical Gradient\n",
        "Descent optimization, like Batch Gradient Descent, the batch is taken to be the whole dataset.\n",
        "Although, using the whole dataset is really useful for getting to the minima in a less noisy and less\n",
        "random manner, but the problem arises when our datasets gets big.\n",
        "Adam is a replacement optimization algorithm for stochastic gradient descent for training deep\n",
        "learning models. Adam combines the best properties of the AdaGrad and RMSProp algorithms to\n",
        "provide an optimization algorithm that can handle sparse gradients on noisy problems.\n",
        "The RMSprop optimizer is similar to the gradient descent algorithm with momentum. The RMSprop\n",
        "optimizer restricts the oscillations in the vertical direction. Therefore, we can increase our learning\n",
        "rate and our algorithm could take larger steps in the horizontal direction converging faster. The\n",
        "difference between RMSprop and gradient descent is on how the gradients are calculated. The\n",
        "following equations show how the gradients are calculated for the RMSprop and gradient descent\n",
        "with momentum. The value of momentum is denoted by beta and is usually set to 0.9.\n",
        "Nadam combines NAG and Adam. Nadam is employed for noisy gradients or for gradients with high\n",
        "curvatures. The learning process is accelerated by summing up the exponential decay of the moving\n",
        "averages for the previous and current gradient"
      ],
      "metadata": {
        "id": "MXA_q_5u1uqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rkZ_-h3e1-yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code"
      ],
      "metadata": {
        "id": "HpRsw98S1_pu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qoBi4UwV1r1u",
        "outputId": "6aa047d2-5525-4be6-e86f-c1c1a88a2f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 3s 0us/step\n",
            "169017344/169001437 [==============================] - 3s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 29s 142ms/step - loss: 4.1827 - accuracy: 0.0798 - val_loss: 3.8705 - val_accuracy: 0.1121\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 20s 100ms/step - loss: 3.7465 - accuracy: 0.1387 - val_loss: 3.6870 - val_accuracy: 0.1501\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 20s 100ms/step - loss: 3.6081 - accuracy: 0.1631 - val_loss: 3.6130 - val_accuracy: 0.1659\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 20s 100ms/step - loss: 3.5143 - accuracy: 0.1774 - val_loss: 3.5310 - val_accuracy: 0.1818\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 21s 104ms/step - loss: 3.4462 - accuracy: 0.1930 - val_loss: 3.5124 - val_accuracy: 0.1863\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 20s 101ms/step - loss: 3.3704 - accuracy: 0.2039 - val_loss: 3.5075 - val_accuracy: 0.1853\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 21s 105ms/step - loss: 3.3069 - accuracy: 0.2182 - val_loss: 3.4107 - val_accuracy: 0.2034\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 22s 112ms/step - loss: 3.2549 - accuracy: 0.2252 - val_loss: 3.3697 - val_accuracy: 0.2095\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 20s 102ms/step - loss: 3.2137 - accuracy: 0.2324 - val_loss: 3.3682 - val_accuracy: 0.2113\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 22s 109ms/step - loss: 3.1717 - accuracy: 0.2417 - val_loss: 3.3514 - val_accuracy: 0.2157\n",
            "Epoch 1/10\n",
            "50/50 [==============================] - 18s 348ms/step - loss: 3.0565 - accuracy: 0.2665 - val_loss: 3.2796 - val_accuracy: 0.2295\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 18s 358ms/step - loss: 3.0273 - accuracy: 0.2727 - val_loss: 3.2689 - val_accuracy: 0.2309\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 17s 339ms/step - loss: 3.0176 - accuracy: 0.2747 - val_loss: 3.2636 - val_accuracy: 0.2327\n",
            "Epoch 4/10\n",
            "44/50 [=========================>....] - ETA: 1s - loss: 3.0123 - accuracy: 0.2760"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-f0acd5bc2071>\", line 16, in <module>\n",
            "    model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 910, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 942, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3131, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 603, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,models,datasets\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "(train_images,train_labels),(test_images,test_labels)=datasets.cifar100.load_data()\n",
        "train_images=train_images/255\n",
        "test_images=test_images/255\n",
        "base=VGG16(include_top=False,input_shape=(32,32,3))\n",
        "base.trainable=False\n",
        "model=models.Sequential()\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1200,activation=\"relu\"))\n",
        "model.add(layers.Dense(100,activation=\"softmax\"))\n",
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=200)\n",
        "model.compile(optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)\n",
        "model.compile(optimizer=\"adagrad\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)\n",
        "model.compile(optimizer=\"sgd\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)\n",
        "model.compile(optimizer=\"nadam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels),steps_per_epoch=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rh7VhXNK2UGD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}